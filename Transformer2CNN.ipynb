{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer2CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "PZ6qe5Ef2zml",
        "H1KhbQsq2zmp",
        "hwCYk50F2zmx",
        "t025xNjnay7S",
        "b8ziJVQN2zm6",
        "wH5mZRb8MSi8",
        "8cqF7JU52zna",
        "I3zL8awdlkZc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marble999/bert-distillation/blob/master/Transformer2CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhZJ93oRGySr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -nc http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -n glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PZ6qe5Ef2zml"
      },
      "source": [
        "# Transformer to CNN: Label-scarce distillation for efficient text classification\n",
        "Source code for paper submission to NeurIPS Workshop on Compact Deep Neural Networks with Industry Applications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M-q9lQuQtu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "icZ0UsKY2zmo",
        "colab": {}
      },
      "source": [
        "TASK = \"ag_news\" #@param [\"ag_news\", \"dbpedia\", \"yahoo_answers\"]\n",
        "\n",
        "from pathlib import Path\n",
        "PATH = \"drive/My Drive/deep/compact_demo\" #@param {type:\"string\"}\n",
        "PATH = Path(PATH)  \n",
        "#@markdown Path to google drive datasets folder (you can add [this folder](https://drive.google.com/drive/folders/1272ZQbiUr-U8lrKy5EEdvYoVxYT7_cAq?usp=sharing) to your drive)\n",
        "print('TASK: {}, PATH: {}'.format(TASK, PATH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H1KhbQsq2zmp"
      },
      "source": [
        "###Utilities & Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E51PmBFn2zmp",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "\n",
        "def shell_format(path_string):\n",
        "    return str(path_string).replace(' ', '\\ ')\n",
        "\n",
        "\n",
        "def split_data(data, labelled_limit=100, unlabelled_limit=1000):\n",
        "    n_classes = len(set(data.target))\n",
        "    labelled_size = labelled_limit * n_classes\n",
        "    unlabelled_size = unlabelled_limit * n_classes\n",
        "    print('Labelled size: {}, Unlabelled_size: {}'.format(\n",
        "        labelled_size, unlabelled_size))\n",
        "    x_trn, x_val, y_trn, y_val = train_test_split(\n",
        "        data.data,\n",
        "        data.target,\n",
        "        random_state=42,\n",
        "        train_size=labelled_size,\n",
        "        stratify=data.target)\n",
        "    x_tra = x_val[labelled_size:][:unlabelled_size]\n",
        "    x_val = x_val[:labelled_size]\n",
        "    y_tra = y_val[labelled_size:][:unlabelled_size]\n",
        "    y_val = y_val[:labelled_size]\n",
        "    return [np.asarray(a) for a in [x_trn, x_val, x_tra, y_trn, y_val, y_tra]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NLgyf3CA2zmr",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "class LossPlot():\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "\n",
        "    def update(self, value):\n",
        "        self.history.append(value)\n",
        "\n",
        "    def plot(self):\n",
        "        clear_output(wait=True)\n",
        "        plt.plot(self.history)\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-x_t5r-BeWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q finetune==0.4.1\n",
        "!python -m spacy download en\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from finetune import Classifier, Regressor\n",
        "from finetune.utils import iter_data\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "def process_proba(proba):\n",
        "    # Convert normal predict_proba output dict into a nparray\n",
        "    n_classes = len(proba[0])\n",
        "    n_samples = len(proba)\n",
        "    print('n_classes: {}, n_samples: {}'.format(n_classes, n_samples))\n",
        "    return np.array(\n",
        "        [[proba[i][j] for j in range(n_classes)] for i in range(n_samples)])\n",
        "\n",
        "\n",
        "class OpenAIClassifier(Classifier):\n",
        "    def _predict_proba_op(self, logits, **kwargs):\n",
        "        return logits\n",
        "\n",
        "    def scorer(self, target, pred):\n",
        "        return f1_score(target, pred, average='weighted')\n",
        "\n",
        "    def fit(self, x_trn, x_val, y_trn, y_val, val_freq=5):\n",
        "        lossplot = LossPlot()\n",
        "        self.config.val_interval = int(\n",
        "            len(x_trn) / self.config.batch_size / val_freq)\n",
        "        print('N train: {}, Val interval: {}, Val frequency: {}'.format(\n",
        "            len(x_trn), self.config.val_interval, val_freq))\n",
        "\n",
        "        arr_encoded_trn = self._text_to_ids(x_trn)\n",
        "        arr_encoded_val = self._text_to_ids(x_val)\n",
        "\n",
        "        batch_size = self.config.batch_size\n",
        "        n_batch_train = batch_size * max(len(self.config.visible_gpus), 1)\n",
        "        n_examples = len(x_trn)\n",
        "        n_updates_total = (n_examples // n_batch_train) * self.config.n_epochs\n",
        "        self.label_encoder = self._target_encoder()\n",
        "\n",
        "        ds_trn = (arr_encoded_trn.token_ids, arr_encoded_trn.mask,\n",
        "                  self.label_encoder.fit_transform(np.asarray(y_trn)))\n",
        "        ds_val = (arr_encoded_val.token_ids, arr_encoded_val.mask,\n",
        "                  self.label_encoder.transform(np.asarray(y_val)))\n",
        "\n",
        "        target_dim = self.label_encoder.target_dim\n",
        "        self._build_model(\n",
        "            n_updates_total=n_updates_total, target_dim=target_dim)\n",
        "        self.is_trained = True\n",
        "\n",
        "        prev_best = global_step = 0\n",
        "\n",
        "        for i in range(self.config.n_epochs):\n",
        "            for xtrn, mtrn, ytrn in iter_data(\n",
        "                    *ds_trn,\n",
        "                    tqdm_desc=\"Training Epoch {}\".format(i),\n",
        "                    n_batch=n_batch_train,\n",
        "                    verbose=self.config.verbose):\n",
        "                self._eval(\n",
        "                    self.target_loss,\n",
        "                    self.train_op,\n",
        "                    feed_dict={\n",
        "                        self.X: xtrn,\n",
        "                        self.M: mtrn,\n",
        "                        self.Y: ytrn,\n",
        "                        self.do_dropout: int(True)\n",
        "                    })\n",
        "\n",
        "                global_step += 1\n",
        "                if global_step % self.config.val_interval == 0 or \\\n",
        "                global_step == n_updates_total - 1:\n",
        "\n",
        "                    with warnings.catch_warnings():\n",
        "                        warnings.filterwarnings(\"ignore\")\n",
        "                        preds = []\n",
        "                        for xval, mval, yval in iter_data(\n",
        "                                *ds_val,\n",
        "                                tqdm_desc=\"Validation\",\n",
        "                                n_batch=n_batch_train):\n",
        "                            output = self._eval(\n",
        "                                self.predict_op,\n",
        "                                feed_dict={\n",
        "                                    self.X: xval,\n",
        "                                    self.M: mval,\n",
        "                                    self.do_dropout: int(False)\n",
        "                                })\n",
        "                            preds.append(\n",
        "                                self.label_encoder.inverse_transform(\n",
        "                                    output.get(self.predict_op)))\n",
        "\n",
        "                    preds = np.concatenate(preds).tolist()\n",
        "                    score = self.scorer(y_val, preds)\n",
        "                    if score > prev_best:\n",
        "                        prev_best = score\n",
        "                        if self.config.autosave_path:\n",
        "                            self.save(self.config.autosave_path)\n",
        "                    lossplot.update(score)\n",
        "                    lossplot.plot()\n",
        "        return prev_best"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UHRMWahD2zmu",
        "colab": {}
      },
      "source": [
        "!wget -q -nc http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -qn glove.6B.zip\n",
        "\n",
        "def glove_matrix(tok, emb_dim=100, n_special=1):\n",
        "    with open('glove.6B.{}d.txt'.format(emb_dim)) as file:\n",
        "        emb_matrix = np.zeros((len(tok.word_index) + n_special, emb_dim))\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            token_id = tok.word_index.get(word)\n",
        "            if token_id is not None:\n",
        "                emb_matrix[token_id] = values[1:]\n",
        "    return emb_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yaIRnQy_2zmv",
        "colab": {}
      },
      "source": [
        "from keras import (layers, optimizers, models, losses, \n",
        "                   metrics, callbacks, preprocessing)\n",
        "\n",
        "def model_input_with_optional_embedding(\n",
        "    maxlen, vocab_size, emb_dim, use_embedding):\n",
        "    inp = layers.Input(shape=(maxlen, ))\n",
        "    z = layers.Embedding(vocab_size + 1, emb_dim)(inp)\n",
        "    if not use_embedding:\n",
        "        inp = layers.Input(shape=(maxlen, emb_dim, ))\n",
        "        z = inp\n",
        "    return inp, z\n",
        "\n",
        "def blendcnn(maxlen,\n",
        "             vocab_size,\n",
        "             output_dim,\n",
        "             emb_dim=100,\n",
        "             n_layers=8,\n",
        "             n_filters=100,\n",
        "             kernel_size=5,\n",
        "             use_embedding=True):\n",
        "\n",
        "    inp, z = model_input_with_optional_embedding(\n",
        "        maxlen, vocab_size, emb_dim, use_embedding)\n",
        "        \n",
        "    gmaxpools = []\n",
        "    for i in range(n_layers):\n",
        "        z = layers.Conv1D(\n",
        "            n_filters, kernel_size, padding='same', activation='relu')(z)\n",
        "        gmaxpools.append(layers.GlobalMaxPool1D()(z))\n",
        "        z = layers.MaxPool1D()(z)\n",
        "    z = layers.Concatenate()(gmaxpools)\n",
        "\n",
        "    for i in range(2):\n",
        "        z = layers.Dense(768, activation='relu')(z)\n",
        "\n",
        "    z = layers.Dense(output_dim)(z)\n",
        "    return models.Model(inp, z)\n",
        "\n",
        "\n",
        "def stackcnn(maxlen,\n",
        "             vocab_size,\n",
        "             output_dim,\n",
        "             emb_dim=100,\n",
        "             n_layers=8,\n",
        "             n_filters=100,\n",
        "             kernel_size=5,\n",
        "             use_embedding=True):\n",
        "    inp, z = model_input_with_optional_embedding(\n",
        "        maxlen, vocab_size, emb_dim, use_embedding)\n",
        "\n",
        "    for i in range(n_layers):\n",
        "        z = layers.Conv1D(\n",
        "            n_filters, kernel_size, padding='same', activation='relu')(z)\n",
        "        z = layers.MaxPool1D()(z)\n",
        "\n",
        "    z = layers.GlobalMaxPool1D()(z)\n",
        "    for i in range(2):\n",
        "        z = layers.Dense(100, activation='relu')(z)\n",
        "\n",
        "    z = layers.Dense(output_dim)(z)\n",
        "    return models.Model(inp, z)\n",
        "\n",
        "\n",
        "def kimcnn(maxlen,\n",
        "           vocab_size,\n",
        "           output_dim,\n",
        "           emb_dim=100,\n",
        "           n_filters=100,\n",
        "           kernel_sizes=[3, 4, 5],\n",
        "           n_layers=1,\n",
        "           use_embedding=True):\n",
        "\n",
        "    inp, z = model_input_with_optional_embedding(\n",
        "        maxlen, vocab_size, emb_dim, use_embedding)\n",
        "\n",
        "    conv_blocks = []\n",
        "    for sz in kernel_sizes:\n",
        "        conv = layers.Conv1D(\n",
        "            n_filters, kernel_size=sz, padding='same', activation='relu')(z)\n",
        "        conv = layers.GlobalMaxPool1D()(conv)\n",
        "        conv_blocks.append(conv)\n",
        "    z = layers.Concatenate()(conv_blocks)\n",
        "    z = layers.Dense(output_dim)(z)\n",
        "    return models.Model(inp, z)\n",
        "\n",
        "\n",
        "def bilstm(maxlen,\n",
        "           vocab_size,\n",
        "           output_dim,\n",
        "           emb_dim=100,\n",
        "           n_filters=100,\n",
        "           n_layers=2,\n",
        "           use_embedding=True):\n",
        "    \n",
        "    inp, z = model_input_with_optional_embedding(\n",
        "        maxlen, vocab_size, emb_dim, use_embedding)\n",
        "    \n",
        "    for i in range(n_layers - 1):\n",
        "        z = layers.Bidirectional(\n",
        "            layers.CuDNNLSTM(n_filters, return_sequences=True))(z)\n",
        "    z = layers.Bidirectional(layers.CuDNNLSTM(n_filters))(z)\n",
        "    z = layers.Dense(output_dim)(z)\n",
        "    return models.Model(inp, z)\n",
        "\n",
        "\n",
        "class KerasSaver(callbacks.Callback):\n",
        "    def __init__(self, val_data, emb_labels=None, score_threshold=0):\n",
        "        super().__init__()\n",
        "        self.val_data = val_data\n",
        "        self.prev_best = 0\n",
        "        self.score_threshold = score_threshold\n",
        "        self.lossplot = LossPlot()\n",
        "        self.emb_labels = emb_labels\n",
        "        self.scorer = self.logits_scorer\n",
        "        if emb_labels:\n",
        "            self.scorer = self.emb_labels_scorer\n",
        "\n",
        "    def logits_scorer(self, target, pred):\n",
        "        return f1_score(target, np.argmax(pred, axis=1), average='weighted')\n",
        "\n",
        "    def emb_labels_scorer(self, target, pred):\n",
        "        nearest_labels = np.argmax(\n",
        "            cosine_similarity(pred, self.emb_labels), axis=1)\n",
        "        return f1_score(target, nearest_labels, average='weighted')\n",
        "\n",
        "    def validate_and_plot(self):\n",
        "        x, y = self.val_data\n",
        "        score = self.scorer(y, self.model.predict(x))\n",
        "        self.lossplot.update(score)\n",
        "        if score > self.prev_best:\n",
        "            models.save_model(self.model, 'model')\n",
        "            self.prev_best = score\n",
        "            self.lossplot.plot()\n",
        "            print('Best score: {}'.format(self.prev_best))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.validate_and_plot()\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        if self.prev_best > self.score_threshold:\n",
        "            self.validate_and_plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hwCYk50F2zmx"
      },
      "source": [
        "###Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VTtVFY-F2zmy",
        "colab": {}
      },
      "source": [
        "path = shell_format(PATH/'{}_csv.tar.gz'.format(TASK))\n",
        "!tar -xzf {path}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e4e1CRXK2zm1",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('{}_csv/train.csv'.format(TASK), header=None)\n",
        "data.dropna(inplace=True)\n",
        "data['data'] = data[1] + ' ' + data[2]\n",
        "if TASK == 'yahoo_answers': \n",
        "    data.data = data.data + ' ' + data[3]\n",
        "data['target'] = data[0] - 1  # Convert to zero indexing\n",
        "classes = {\n",
        "    'ag_news': ['world', 'sports', 'business', 'science technology'],\n",
        "    'dbpedia': ['company', 'educational institution', 'artist', 'athlete',\n",
        "                'office holder', 'mean of transportation', 'building', \n",
        "                'natural place', 'village', 'animal', 'plant', 'album', 'film', \n",
        "                'written work'],\n",
        "    'yahoo_answers': ['society culture', 'science mathematics', 'health',\n",
        "                      'education reference', 'computers internet', 'sports',\n",
        "                      'business finance', 'entertainment music', \n",
        "                      'family relationships', 'politics government']\n",
        "}\n",
        "x_trn, x_val, x_tra, y_trn, y_val, y_tra = split_data(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t025xNjnay7S",
        "colab_type": "text"
      },
      "source": [
        "###Train simple classifiers as baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iojaC5YT2zm3",
        "colab": {}
      },
      "source": [
        "# fastText\n",
        "!wget -q -nc https://github.com/facebookresearch/fastText/archive/v0.1.0.zip\n",
        "!unzip -qn v0.1.0.zip\n",
        "%cd fastText-0.1.0\n",
        "!make -s\n",
        "%cd -\n",
        "\n",
        "from string import ascii_letters\n",
        "def format_x(string):\n",
        "    return ''.join([c for c in string if c in (ascii_letters + ' ')]).lower()\n",
        "\n",
        "def format_example(x, y):\n",
        "    return '__label__{} {}'.format(x, y)\n",
        "\n",
        "def write_fasttext_data(x, y, filename):\n",
        "    open(filename, 'w').write('\\n'.join([\n",
        "        format_example(y[i], format_x(x[i])) for i in range(len(x))\n",
        "    ]))\n",
        "        \n",
        "write_fasttext_data(x_trn, y_trn, 'trn')\n",
        "write_fasttext_data(x_val, y_val, 'val')\n",
        "\n",
        "ft = \"fastText-0.1.0/fasttext\"\n",
        "!{ft} supervised -input trn -output model -epoch 2048\n",
        "!{ft} test model.bin val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73HybHfsbAVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import *\n",
        "from sklearn.svm import *\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# pipe = make_pipeline(TfidfVectorizer(), RidgeClassifier())\n",
        "pipe = make_pipeline(TfidfVectorizer(), LinearSVC())\n",
        "pipe.fit(x_trn, y_trn)\n",
        "f1_score(y_val, pipe.predict(x_val), average='weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b8ziJVQN2zm6"
      },
      "source": [
        "###Fine-tune OpenAI Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hj71VqKN2zm9",
        "colab": {}
      },
      "source": [
        "model = OpenAIClassifier(autosave_path='model', lm_loss_coef=0.5)\n",
        "model.fit(x_trn, x_val, y_trn, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEGsRu9GrG5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = shell_format(PATH/'{}_openai_classifier'.format(TASK))\n",
        "!cp -a model {path}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH5mZRb8MSi8",
        "colab_type": "text"
      },
      "source": [
        "###Setup for distillation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhYBJYEaMbou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate distillation logits\n",
        "model = OpenAIClassifier.load(PATH/'{}_openai_classifier'.format(TASK))\n",
        "distill_logits = process_proba(model.predict_proba(np.hstack([x_trn, x_tra])))\n",
        "np.save(PATH/'{}_y_combined_logits_trn.npy'.format(TASK), distill_logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB6ce-FTZOaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit tokenizer on dataset\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tok = Tokenizer()\n",
        "tok.fit_on_texts(x_trn)\n",
        "pickle.dump(tok, open(PATH/'{}_tok.pkl'.format(TASK), 'wb'), \n",
        "            protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8cqF7JU52zna"
      },
      "source": [
        "###Train student model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "74lXH8WR2zna",
        "colab": {}
      },
      "source": [
        "DISTILL_MODE = \"logits\" #@param [\"none\", \"logits\"]  \n",
        "#@markdown 'none' -> original labels, logits -> normal distillation\n",
        "STUDENT_MODEL = \"8stackcnn\" #@param [\"3blendcnn\", \"8blendcnn\", \"1kimcnn\", \"2bilstm\", \"3stackcnn\", \"8stackcnn\"]\n",
        "#@markdown Integer prefix denotes number of layers\n",
        "USE_PSEUDO_LOGITS = True #@param [\"True\", \"False\"] {type:\"raw\"}\n",
        "#@markdown 'True' -> Labelled + Unlabelled data, 'False' -> Only Labelled data\n",
        "\n",
        "print('Distill mode:', DISTILL_MODE)\n",
        "print('Student model:', STUDENT_MODEL)\n",
        "print('Use pseudo logits:', USE_PSEUDO_LOGITS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7IE2W3md2znc",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def choose_x_trn(x_trn, x_tra, distill_mode, use_pseudo_logits):\n",
        "    if (use_pseudo_logits and distill_mode != 'none'):\n",
        "        return np.hstack([x_trn, x_tra])\n",
        "    else:\n",
        "        return x_trn\n",
        "\n",
        "def choose_y_trn(y_trn, task, distill_mode, use_pseudo_logits):\n",
        "    if distill_mode == 'none':\n",
        "        return to_categorical(y_trn)\n",
        "    else:\n",
        "        pseudo_logits = np.load(\n",
        "            PATH/'{}_y_combined_{}_trn.npy'.format(task, distill_mode))\n",
        "        if use_pseudo_logits:\n",
        "            return pseudo_logits\n",
        "        else:\n",
        "            return pseudo_logits[:len(y_trn)]\n",
        "    \n",
        "MAXLEN = 1000\n",
        "tok = pickle.load(open(PATH/'{}_tok.pkl'.format(TASK), 'rb'))\n",
        "\n",
        "data_trn = [pad_sequences(tok.texts_to_sequences(\n",
        "    choose_x_trn(x_trn, x_tra, DISTILL_MODE, USE_PSEUDO_LOGITS)), MAXLEN), \n",
        "    choose_y_trn(y_trn, TASK, DISTILL_MODE, USE_PSEUDO_LOGITS)]\n",
        "data_val = [pad_sequences(tok.texts_to_sequences(x_val), MAXLEN), y_val]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_BmHJ2DT2zne",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "architecture = {\n",
        "    'blendcnn':blendcnn, \n",
        "    'kimcnn':kimcnn, \n",
        "    'bilstm':bilstm,\n",
        "    'stackcnn':stackcnn\n",
        "}[STUDENT_MODEL[1:]]\n",
        "\n",
        "model = architecture(\n",
        "    maxlen=MAXLEN, vocab_size=len(tok.word_index), \n",
        "    output_dim=data_trn[1].shape[1], n_layers=int(STUDENT_MODEL[0])\n",
        ")\n",
        "model.compile(optimizers.Adam(), losses.mean_absolute_error)\n",
        "model.layers[1].set_weights([glove_matrix(tok)])\n",
        "    \n",
        "saver = KerasSaver(data_val)\n",
        "with warnings.catch_warnings():\n",
        "    # F-score undefined and slow method on_batch_end warnings\n",
        "    warnings.simplefilter('ignore')  \n",
        "    model.fit(*data_trn, epochs=10, batch_size=64, \n",
        "              verbose=2, callbacks=[saver])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3zL8awdlkZc",
        "colab_type": "text"
      },
      "source": [
        "###Convert student model to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_IgB0Z1DJpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone -q https://github.com/amir-abdi/keras_to_tensorflow.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENewxSeUChmS",
        "colab_type": "code",
        "collapsed": true,
        "colab": {}
      },
      "source": [
        "architecture = {\n",
        "    'blendcnn':blendcnn, \n",
        "    'kimcnn':kimcnn, \n",
        "    'bilstm':bilstm,\n",
        "    'stackcnn':stackcnn\n",
        "}[STUDENT_MODEL[1:]]\n",
        "\n",
        "MAXLEN = 1000\n",
        "model = architecture(\n",
        "    # Standard vocab_size and output_dim for consistency across models\n",
        "    maxlen=MAXLEN, vocab_size=20000, \n",
        "    output_dim=10, n_layers=int(STUDENT_MODEL[0])\n",
        ")\n",
        "model.summary()\n",
        "model.save('model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQb95tpHmc2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved_model_name = 'model'\n",
        "!python keras_to_tensorflow/keras_to_tensorflow.py \\\n",
        "--input_model={saved_model_name} \\\n",
        "--output_model={saved_model_name}.pb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXk2jRhMYB5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.backend.clear_session()\n",
        "model = models.load_model(saved_model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsex6-emXlI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.contrib import lite\n",
        "converter = lite.TFLiteConverter.from_frozen_graph(\n",
        "    graph_def_file='{}.pb'.format(saved_model_name), \n",
        "    input_arrays=[model.input.op.name], \n",
        "    output_arrays=[model.output.op.name]\n",
        ")\n",
        "for use_quantize in [True, False]:\n",
        "    print('Use quantize:', use_quantize)\n",
        "    converter.post_training_quantize=use_quantize\n",
        "    converter.allow_custom_ops=True\n",
        "    tflite_model = converter.convert()\n",
        "    open('{}.tflite'.format(saved_model_name), 'wb').write(tflite_model)\n",
        "    !du -sh model.tflite"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}